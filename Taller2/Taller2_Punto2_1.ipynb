{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker==0.7.2 in ./.venv/lib/python3.10/site-packages (0.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers\n",
    "!pip install pyspellchecker==0.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, f_classif\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from transformers import pipeline\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from Utils.MetricasModelos import ModelMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrtographyCorrector:\n",
    "    def __init__(self, language='es', dictionary_file='./Data/diccionario.txt'):\n",
    "        self.spell = SpellChecker(language=language)\n",
    "        self.dictionary = self.load_dictionary(dictionary_file)\n",
    "\n",
    "    def load_dictionary(self, dictionary_file):\n",
    "        with open(dictionary_file, 'r', encoding='utf-8') as file:\n",
    "            return file.read().splitlines()\n",
    "\n",
    "    def correct_sentence(self, sentence):\n",
    "        words = sentence.split()\n",
    "        corrected_words = [self.correct_word(word) for word in words]\n",
    "        return ' '.join(corrected_words)\n",
    "\n",
    "    def correct_word(self, word):\n",
    "        if self.spell.correction(word) == word:\n",
    "            return word\n",
    "        else:\n",
    "            suggestions = list(self.spell.candidates(word))\n",
    "            matched_suggestions = [s for s in suggestions if s in self.dictionary]\n",
    "\n",
    "            if matched_suggestions:\n",
    "                corrected_word = random.choice(matched_suggestions)\n",
    "            else:\n",
    "                corrected_word = str(suggestions[0])\n",
    "\n",
    "            return corrected_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>FICK YESSSSSS.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8319</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Why are people talking about microsoft buying ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9181</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Nvidia's ready to announce the bad stuff.. Rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7841</th>\n",
       "      <td>MaddenNFL</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Gee. I didn't realize Madden NFL needed QBs fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>ApexLegends</td>\n",
       "      <td>Positive</td>\n",
       "      <td>The game is an absolute shredder!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>GrandTheftAuto(GTA)</td>\n",
       "      <td>Positive</td>\n",
       "      <td>It's about fricking time!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>Overwatch</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Initially, I didn't like the idea, but I would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>CallOfDutyBlackopsColdWar</td>\n",
       "      <td>Positive</td>\n",
       "      <td>This video has only brought back good memories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>CallOfDutyBlackopsColdWar</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>The very best and the game isn’t out yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>Cyberpunk2077</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Congrats to the team!  look forward to playing!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        TweetID Sentiment  \\\n",
       "2415                Borderlands  Positive   \n",
       "8319                  Microsoft  Negative   \n",
       "9181                     Nvidia   Neutral   \n",
       "7841                  MaddenNFL  Negative   \n",
       "575                 ApexLegends  Positive   \n",
       "...                         ...       ...   \n",
       "5048        GrandTheftAuto(GTA)  Positive   \n",
       "9427                  Overwatch  Negative   \n",
       "1653  CallOfDutyBlackopsColdWar  Positive   \n",
       "1675  CallOfDutyBlackopsColdWar   Neutral   \n",
       "3834              Cyberpunk2077  Positive   \n",
       "\n",
       "                                              TweetText  \n",
       "2415                                     FICK YESSSSSS.  \n",
       "8319  Why are people talking about microsoft buying ...  \n",
       "9181  Nvidia's ready to announce the bad stuff.. Rea...  \n",
       "7841  Gee. I didn't realize Madden NFL needed QBs fo...  \n",
       "575                 The game is an absolute shredder!!!  \n",
       "...                                                 ...  \n",
       "5048                          It's about fricking time!  \n",
       "9427  Initially, I didn't like the idea, but I would...  \n",
       "1653  This video has only brought back good memories...  \n",
       "1675           The very best and the game isn’t out yet  \n",
       "3834    Congrats to the team!  look forward to playing!  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/Sentiment_Data/twitter_training.csv',\n",
    "                       header=None,\n",
    "                       names=['TweetID', 'Sentiment', 'TweetText'],)\n",
    "\n",
    "df_train = df.sample(n=1000, random_state=1)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno -3] Temporary\n",
      "[nltk_data]     failure in name resolution>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno -3] Temporary\n",
      "[nltk_data]     failure in name resolution>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n",
      "[nltk_data]     Temporary failure in name resolution>\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Tokenización\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Lematización\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(text)])\n",
    "\n",
    "def lemmatize_text_lang(text, language):\n",
    "    nlp = spacy.load(f\"{language}_core_news_sm\")\n",
    "    doc = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in doc])\n",
    "\n",
    "# Modificación de la lista de stopwords\n",
    "def modify_stopwords(text, new_stopwords=[], remove_stopwords=[]):\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "    # Agrega nuevas stopwords\n",
    "    for word in new_stopwords:\n",
    "        stop_words.add(word)\n",
    "\n",
    "    # Elimina stopwords\n",
    "    for word in remove_stopwords:\n",
    "        stop_words.discard(word)\n",
    "\n",
    "    return ' '.join([word for word in word_tokenize(text) if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at j-hartmann/sentiment-roberta-large-english-3-classes were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis = pipeline(task=\"sentiment-analysis\",\n",
    "                              framework=\"pt\",\n",
    "                              model=\"j-hartmann/sentiment-roberta-large-english-3-classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['TweetText'] = df_train['TweetText'].astype(str)\n",
    "df_train['Sentiment'] = df_train['Sentiment'].str.lower()\n",
    "list_text = df_train['TweetText'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sentiment_analysis(list_text)\n",
    "df_train['HuggingFace_Sentiment'] = [result['label'] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/diego/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_label(score):\n",
    "    if score > 0.05:\n",
    "        label = 'positive'\n",
    "    elif score < -0.05:\n",
    "        label = 'negative'\n",
    "    else:\n",
    "        label = 'neutral'\n",
    "    return label\n",
    "\n",
    "df_train['nltk_sentiment'] = df_train['TweetText'].apply(\n",
    "    lambda x: get_sentiment_label(sia.polarity_scores(x)['compound']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        TweetID Sentiment  \\\n",
      "2415                Borderlands  positive   \n",
      "8319                  Microsoft  negative   \n",
      "9181                     Nvidia   neutral   \n",
      "7841                  MaddenNFL  negative   \n",
      "575                 ApexLegends  positive   \n",
      "...                         ...       ...   \n",
      "5048        GrandTheftAuto(GTA)  positive   \n",
      "9427                  Overwatch  negative   \n",
      "1653  CallOfDutyBlackopsColdWar  positive   \n",
      "1675  CallOfDutyBlackopsColdWar   neutral   \n",
      "3834              Cyberpunk2077  positive   \n",
      "\n",
      "                                              TweetText HuggingFace_Sentiment  \\\n",
      "2415                                      fick yessssss              positive   \n",
      "8319  why are people talking about microsoft buying ...              negative   \n",
      "9181  nvidias ready to announce the bad stuff really...              negative   \n",
      "7841  gee i didnt realize madden nfl needed qbs for ...              negative   \n",
      "575                    the game is an absolute shredder              positive   \n",
      "...                                                 ...                   ...   \n",
      "5048                            its about fricking time              positive   \n",
      "9427  initially i didnt like the idea but i would pr...              negative   \n",
      "1653  this video has only brought back good memories...              positive   \n",
      "1675            the very best and the game isnt out yet               neutral   \n",
      "3834      congrats to the team  look forward to playing              positive   \n",
      "\n",
      "     nltk_sentiment  \n",
      "2415        neutral  \n",
      "8319       negative  \n",
      "9181       negative  \n",
      "7841        neutral  \n",
      "575         neutral  \n",
      "...             ...  \n",
      "5048        neutral  \n",
      "9427       negative  \n",
      "1653       positive  \n",
      "1675       positive  \n",
      "3834       positive  \n",
      "\n",
      "[1000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalizacion y limpieza\n",
    "df_train['TweetText'] = df_train['TweetText'].str.lower()\n",
    "\n",
    "def remove_symbols(text, regex):\n",
    "    return re.sub(regex, '', text)\n",
    "\n",
    "df_train['TweetText'] = df_train['TweetText'].apply(lambda x: remove_symbols(x, r'[^\\w\\s]'))\n",
    "df_train['TweetText'] = df_train['TweetText'].apply(lambda x: remove_symbols(x, r'\\d+'))\n",
    "df_train['TweetText'] = df_train['TweetText'].str.lower()\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['TweetText'] = df_train['TweetText'].astype(str)\n",
    "list_text = df_train['TweetText'].tolist()\n",
    "results = sentiment_analysis(list_text)\n",
    "df_train['Preprocessing+HuggingFace_Sentiment'] = [result['label'] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/diego/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_label(score):\n",
    "    if score > 0.05:\n",
    "        label = 'positive'\n",
    "    elif score < -0.05:\n",
    "        label = 'negative'\n",
    "    else:\n",
    "        label = 'neutral'\n",
    "    return label\n",
    "\n",
    "df_train['Preprocessing+nltk_sentiment'] = df_train['TweetText'].apply(\n",
    "    lambda x: get_sentiment_label(sia.polarity_scores(x)['compound']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m [20-Jun-23 12:20:35] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating precision\u001b[0m\n",
      "\u001b[32m [20-Jun-23 12:20:35] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating accuracy\u001b[0m\n",
      "\u001b[32m [20-Jun-23 12:20:35] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating recall\u001b[0m\n",
      "\u001b[32m [20-Jun-23 12:20:35] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating specificity\u001b[0m\n",
      "\u001b[32m [20-Jun-23 12:20:35] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating precision\u001b[0m\n",
      "\u001b[32m [20-Jun-23 12:20:35] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating accuracy\u001b[0m\n",
      "\u001b[32m [20-Jun-23 12:20:35] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating recall\u001b[0m\n",
      "\u001b[32m [20-Jun-23 12:20:36] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating specificity\u001b[0m\n",
      "\u001b[32m [20-Jun-23 12:20:36] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating precision\u001b[0m\n",
      "\u001b[32m [20-Jun-23 12:20:36] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating accuracy\u001b[0m\n",
      "\u001b[32m [20-Jun-23 12:20:36] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating recall\u001b[0m\n",
      "\u001b[32m [20-Jun-23 12:20:36] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating specificity\u001b[0m\n",
      "\u001b[32m [20-Jun-23 12:20:36] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating precision\u001b[0m\n",
      "\u001b[32m [20-Jun-23 12:20:36] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating accuracy\u001b[0m\n",
      "\u001b[32m [20-Jun-23 12:20:36] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating recall\u001b[0m\n",
      "\u001b[32m [20-Jun-23 12:20:36] [INFO] [ModelMetrics]  =>>>  \u001b[0m Calculating specificity\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Exactitud</th>\n",
       "      <th>Sensibilidad</th>\n",
       "      <th>Especificidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HuggingFace</th>\n",
       "      <td>0.512</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.833519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLTK</th>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.793585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuggingFace+Preprocessing</th>\n",
       "      <td>0.496</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.827797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLTK+Preprocessing</th>\n",
       "      <td>0.409</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.794667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Precision  Exactitud  Sensibilidad  Especificidad\n",
       "HuggingFace                    0.512      0.512         0.512       0.833519\n",
       "NLTK                           0.405      0.405         0.405       0.793585\n",
       "HuggingFace+Preprocessing      0.496      0.496         0.496       0.827797\n",
       "NLTK+Preprocessing             0.409      0.409         0.409       0.794667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas = ModelMetrics()\n",
    "\n",
    "df_metrics = {'Precision': [], 'Exactitud': [], 'Sensibilidad': [], 'Especificidad': []}\n",
    "for pred in [df_train['HuggingFace_Sentiment'],\n",
    "             df_train['nltk_sentiment'],\n",
    "             df_train['Preprocessing+HuggingFace_Sentiment'],\n",
    "             df_train['Preprocessing+nltk_sentiment']]:\n",
    "    df_metrics['Precision'].append(metricas.precision(df_train['Sentiment'], pred))\n",
    "    df_metrics['Exactitud'].append(metricas.accuracy(df_train['Sentiment'], pred))\n",
    "    df_metrics['Sensibilidad'].append(metricas.recall(df_train['Sentiment'], pred))\n",
    "    df_metrics['Especificidad'].append(metricas.specificity(df_train['Sentiment'], pred))\n",
    "df_metrics = pd.DataFrame(df_metrics, index=['HuggingFace',\n",
    "                                             'NLTK',\n",
    "                                             'HuggingFace+Preprocessing',\n",
    "                                             'NLTK+Preprocessing'])\n",
    "df_metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este caso en particular con la base de datos que se tiene, no se observa buenas metricas pero tambien hay que tener que las metricas que se estan generando son medias de las 3 etiquetas. Toca revisar a fondo cuales de las etiquetas logra identificar mejor, además se podria utilizar un corrector ortografico para ver el comportamiento tambien se puede realizar eliminacion de stopwords y otros procesos para poder mejorar los resultados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ¿Cuáles son los diferentes tipos de análisis de sentimientos?**\n",
    "\n",
    "Existen varios tipos de análisis de sentimientos, incluyendo:\n",
    "\n",
    "- **Análisis de sentimientos a nivel de polaridad:** Este tipo de análisis se enfoca en identificar la polaridad general de un texto, es decir, si es positivo, negativo o neutral.\n",
    "\n",
    "- **Análisis de sentimientos a nivel de emoción:** Este tipo va más allá de la polaridad e intenta identificar emociones específicas, como alegría, tristeza, enojo, sorpresa, etc.\n",
    "\n",
    "- **Análisis de sentimientos a nivel de aspecto:** Este tipo de análisis busca identificar sentimientos o emociones relacionados con aspectos específicos dentro de un texto. Por ejemplo, en una revisión de un producto, un usuario podría tener una opinión positiva sobre la duración de la batería, pero una opinión negativa sobre la interfaz de usuario.\n",
    "\n",
    "- **Análisis de sentimientos a nivel de intención:** Este tipo de análisis se enfoca en identificar la intención del autor, como recomendar, no recomendar, comprar, no comprar, etc.\n",
    "\n",
    "**2. ¿Cuáles son los diferentes métodos para el análisis de sentimientos?**\n",
    "\n",
    "Los métodos para el análisis de sentimientos se pueden dividir en dos categorías generales:\n",
    "\n",
    "- **Métodos basados en lexicones:** Estos métodos utilizan listas predefinidas de palabras asociadas con sentimientos positivos o negativos. El análisis de sentimientos se realiza contando la frecuencia de las palabras positivas y negativas y decidiendo la polaridad general del texto.\n",
    "\n",
    "- **Métodos basados en aprendizaje automático:** Estos métodos utilizan técnicas de aprendizaje automático (como la regresión logística, máquinas de vectores de soporte, redes neuronales, etc.) para aprender a partir de un conjunto de datos de entrenamiento etiquetado y luego aplicar este aprendizaje para predecir el sentimiento de los datos no etiquetados.\n",
    "\n",
    "**3. ¿Cuáles son los desafíos del análisis de sentimientos?**\n",
    "\n",
    "El análisis de sentimientos presenta varios desafíos:\n",
    "\n",
    "- **Sarcasmo e ironía:** Estos pueden ser particularmente difíciles de detectar para los algoritmos de análisis de sentimientos, ya que a menudo implican el uso de palabras positivas para expresar sentimientos negativos y viceversa.\n",
    "\n",
    "- **Ambigüedad:** La ambigüedad lingüística puede dificultar la determinación de la polaridad de un texto. Una palabra puede tener diferentes connotaciones dependiendo del contexto en el que se use.\n",
    "\n",
    "- **Aspectos múltiples:** Como se mencionó anteriormente, un texto puede contener sentimientos diferentes hacia diferentes aspectos. Esto puede dificultar la determinación de un sentimiento general.\n",
    "\n",
    "- **Disponibilidad de datos etiquetados:** Para los métodos de aprendizaje automático, se necesita un conjunto de datos de entrenamiento grande y de alta calidad con etiquetas de sentimientos. Estos pueden ser difíciles y costosos de obtener. \n",
    "\n",
    "- **Aspectos culturales y de lenguaje:** Los sentimientos pueden expresarse de manera diferente en diferentes culturas o en diferentes idiomas. Esto puede hacer que el análisis de sentimientos sea más complejo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
